<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Pervasive and Ubiquitious computing Natural user interfaces
 applications off desktop physical linteraction moving away from mouse/keyboard/display natural acations used as input to systems better learnability, easure of use."><title>02-intro-pervasive-and-ubiquitious</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://jethughes.github.io/notes//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://jethughes.github.io/notes/styles.1a1ffb6f8cc2d9990f06b61d70c9b09b.min.css rel=stylesheet><script src=https://jethughes.github.io/notes/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://jethughes.github.io/notes/js/popover.688c5dcb89a57776d7f1cbeaf6f7c44b.min.js></script>
<script>const BASE_URL="https://jethughes.github.io/notes/",fetchData=Promise.all([fetch("https://jethughes.github.io/notes/indices/linkIndex.3319b7ede1d06cb5eb0dce1fb9573509.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://jethughes.github.io/notes/indices/contentIndex.13fa6f5100e36ae2ef337895191b19df.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const n=new URL("https://jethughes.github.io/notes/"),s=n.pathname,o=window.location.pathname,i=s==o,e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=i&&!1;drawGraph("https://jethughes.github.io/notes",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2}),initPopover("https://jethughes.github.io/notes",!0,!0)},init=(e=document)=>{renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/jethughes.github.io\/notes\/js\/router.557a499829be51f9008c6efa5b73602a.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://jethughes.github.io/notes/js/search.cf33b507388f3dfd5513a2afcda7af41.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://jethughes.github.io/notes/>Jet's Notes</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>02-intro-pervasive-and-ubiquitious</h1><p class=meta>Last updated March 14, 2023</p><ul class=tags><li><a href=https://jethughes.github.io/notes/tags/lecture/>Lecture</a></li><li><a href=https://jethughes.github.io/notes/tags/info305/>Info305</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents></nav></details></aside><a href=#pervasive-and-ubiquitious-computing><h1 id=pervasive-and-ubiquitious-computing><span class=hanchor arialabel=Anchor># </span>Pervasive and Ubiquitious computing</h1></a><p>Natural user interfaces</p><ul><li>applications off desktop</li><li>physical linteraction moving away from mouse/keyboard/display</li><li>natural acations used as input to systems</li><li>better learnability, easure of use. ⇒ support tasks without changing them</li><li>support special needs people</li></ul><blockquote><p>[!INFO] computer we wear communicate with more locally installed les ubiquitious computers</p></blockquote><p>context awareness</p><ul><li>apps are aware of the environment around the user/the app and can adjus their behaviour to suit it</li></ul><blockquote><p>[!INFO] computer should behave in a more natural way
[!INFO] also aware of our current goals</p></blockquote><p>automatic capture and access</p><ul><li>automatically record and store things to remove the burden from humans and allows us to focus on things we are better at</li></ul><a href=#examples><h1 id=examples><span class=hanchor arialabel=Anchor># </span>Examples</h1></a><p>context awareness
<img src=https://i.imgur.com/NpTeqcL.png alt=|300></p><blockquote><p>[!INFO] phone already knows your location</p></blockquote><blockquote><p>[!INFO] uses electroculography: eye tracking without a camera. wanted to know if you could build a context aware systems based on eye movements: copy, read, write, video, browse, NULL. They achieved 70%-80% accuracy, WITHOUT using complicated machine learning.</p></blockquote><p><img src=https://i.imgur.com/pKl0wQV.png alt="David Lindlbauer, Anna Maria Feit, Otmar Hilliges, Context-Aware Online Adaptation of Mixed Reality Interfaces"></p><blockquote><p>[!INFO] measure cognitive load using pupil dilation. with high cognitive load they show less information on screen to stop from distracting you.</p></blockquote><blockquote><p>[!QUESTION] if they block other stuff while we have high workload, how do we decide which important things to show</p></blockquote><p><img src=https://i.imgur.com/jibhsuL.png alt="Gregory D. Abowd, “Classroom 2000: An Experiment with the Instrumentation of a Living Educational Environment”, IBM Systems Journal, Special issue on Pervasive Computing, Volume 38, Number 4, pp. 508-530, October 1999"></p><blockquote><p>[!INFO] camera is class: idea to show automactically that everything is caputred, audio recording are matched to slides, annotations are shared with the whole class, as well as individual comments. able to split up video to see which parts of the slides are being talked about when. collects a lot of data that can be used later</p></blockquote><blockquote><p>[!QUESTION] auto sharing annotations sounds very easy, i think we should make the <em>default</em> that annotations are shared</p></blockquote><p><img src=https://i.imgur.com/PTijDvG.png alt="Steve Mann, “My “Augmediated” Life What I’ve learned from 35 years of wearing computerized eyewear” IEEE Explore, 2013"></p><blockquote><p>[!INFO] cameras constantly running, recorded his whole life. he is controversial, recording other people.</p></blockquote><blockquote><p>[!INFO] if everything is recorded there is an ethical dilemma, is contanst recording what we really want.</p></blockquote><p><img src=https://i.imgur.com/v9SziUx.png alt="Hodges, et al. SenseCam: A retrospective memory aid. ACM Ubicomp ’06"></p><blockquote><p>[!INFO] same thing: camera constantly running: but neck camera</p></blockquote><blockquote><p>[!INFO] toll gates scanning number plates: initally kept private. can we use it to solve a crime though?</p></blockquote><a href=#tangible-computing><h1 id=tangible-computing><span class=hanchor arialabel=Anchor># </span>Tangible computing</h1></a><ul><li>Directly-manipulable physical interfaces to data and computation</li><li>‘Pure’ form of ubicomp in that there is no computer to be seen</li></ul><p><img src=https://i.imgur.com/mmgQMCY.png alt="H. Ishii, B. Ullmer. Tangible Bits: Towards seamless interfaces between people, bits and atoms"></p><p><img src=https://i.imgur.com/qCWtriU.png alt="1992 – Durrell Bishop&amp;rsquo;s Marble Answering Machine"></p><blockquote><p>[!INFO] message &ldquo;captured in balls&rdquo;</p></blockquote><p><img src=https://i.imgur.com/Uh5rNE5.png alt="Daniel Leithinger, Sean Follmer, Alex Olwal, and Hiroshi Ishii. 2014. Physical telepresence: shape capture and display for embodied, computer-mediated remote collaboration. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST &amp;lsquo;14)."></p><blockquote><p>[!INFO] physical telepresence. physical interaction remotely</p></blockquote><p><img src=https://i.imgur.com/GhglQbZ.png alt="Ryokai, Marti, Ishii. I/O Brush: Drawing with Everyday Objects as Ink. ACM CHI ’04."></p><p><img src=https://i.imgur.com/3LWqoIe.png alt="SoundFORMS: Manipulating Sound Through Touch CHI 2016"></p><a href=#calm-computing><h1 id=calm-computing><span class=hanchor arialabel=Anchor># </span>Calm computing</h1></a><p><img src=https://i.imgur.com/zyEBMGV.png alt="Project Blinkenlights (2001), http://blinkenlights.net, Haus des Lehrers, Berlin, Germany"></p><p><img src=https://i.imgur.com/kUd3zrK.png alt="N. Jeremijenko, LiveWire, Demo ACM Siggraph ’95"></p><blockquote><p>[!INFO] interactive surfaces and spaces. physicalise information. wire was moved according to network traffic</p></blockquote><a href=#input-and-interaction><h1 id=input-and-interaction><span class=hanchor arialabel=Anchor># </span>Input and Interaction</h1></a><p>Google ATAP. track fingers using radar</p><blockquote><p>[!QUESTION] Is it always tracking your finger? what if you do something accidentally</p></blockquote><a href=#wearable-computing><h1 id=wearable-computing><span class=hanchor arialabel=Anchor># </span>Wearable computing</h1></a><p>Thad Starner, starting using weable computing such as glasses. more interested in showing information, than capturing it</p><a href=#challenges><h1 id=challenges><span class=hanchor arialabel=Anchor># </span>Challenges</h1></a><ul><li>What’s difficult about Pervasive and Ubiquitous Computing?</li><li>Requires understanding of sensors and new sensing technologies</li><li>Noisy inputs</li><li>Sensor fusion</li><li>Wireless communication channels</li><li>Power consumption</li><li>Context is only a proxy for human intent</li><li>Unpredictable ussage context in particular for mobile devices</li><li>Require novel user interfaces, limited/different I/O capabilities</li><li>Lack of standardization in interface patterns</li><li>Privacy & Security</li></ul></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://jethughes.github.io/notes/js/graph.afdb02e537635f9a611b53a988e5645b.js></script></div></div><div id=contact_buttons><footer><p>Made with <a href=https://obsidian.md>Obsidian</a> using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, 2023</p><ul><li><a href=/notes/>Home</a></li><li><a href=https://github.com/jethughes>Github</a></li><li><a href=https://www.linkedin.com/in/jet-hughes-b3b688237>LinkedIn</a></li></ul></footer></div></div></body></html>